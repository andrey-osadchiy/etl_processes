# Тема 13. Потоковая обработка данных
## Научиться использовать Apache Kafka с помощью PySpark-заданий
Повторите работу из демонстрации вебинара «Потоковая обработка данных».
Запишите сообщения в топик Apache Kafka® и прочитайте сообщения из топика с помощью PySpark-задания.

Разворачиваем кластер Yandex Data Processing при помощи Yandex Cloud
   ![Скриншот](screenshots/1.png)
Аналогично после танцев с бубнами разворачиваем такой же сервис только для kafka
   ![Скриншот](screenshots/2.png)
   Добавлявем необходмые файлы в специально созданный бакет
   ![Скриншот](screenshots/3.png)
   Создаём первое задание
  ![Скриншот](screenshots/4.png)
  Вроде запустилось
  ![Скриншот](screenshots/5.png)
 Создаём второе задание
   ![Скриншот](screenshots/6.png)
  Удалаяем все наши кластеры ибо едят много денег
  ![Скриншот](screenshots/7.png)
  ![Скриншот](screenshots/8.png)
  ![Скриншот](screenshots/9.png)
